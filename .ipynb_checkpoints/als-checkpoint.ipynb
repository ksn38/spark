{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, explode\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext\n",
    "# sc.setCheckpointDir('checkpoint')\n",
    "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+---+----------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "|household_key|  basket_id|day|product_id|quantity|sales_value|store_id|retail_disc|trans_time|week_no|coupon_disc|coupon_match_disc|\n",
      "+-------------+-----------+---+----------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "|         2375|26984851472|  1|   1004906|       1|       1.39|     364|       -0.6|      1631|      1|          0|                0|\n",
      "|         2375|26984851472|  1|   1033142|       1|       0.82|     364|          0|      1631|      1|          0|                0|\n",
      "|         2375|26984851472|  1|   1036325|       1|       0.99|     364|       -0.3|      1631|      1|          0|                0|\n",
      "+-------------+-----------+---+----------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"/home/ksn38/data/transaction_data.csv\", header=True)\n",
    "data = data.toDF(*[col.lower() for col in data.columns])\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---+-------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "|user_id|  basket_id|day|item_id|quantity|sales_value|store_id|retail_disc|trans_time|week_no|coupon_disc|coupon_match_disc|\n",
      "+-------+-----------+---+-------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "|   2375|26984851472|  1|1004906|       1|       1.39|     364|       -0.6|      1631|      1|          0|                0|\n",
      "|   2375|26984851472|  1|1033142|       1|       0.82|     364|          0|      1631|      1|          0|                0|\n",
      "|   2375|26984851472|  1|1036325|       1|       0.99|     364|       -0.3|      1631|      1|          0|                0|\n",
      "+-------+-----------+---+-------+--------+-----------+--------+-----------+----------+-------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumnRenamed('product_id','item_id').withColumnRenamed('household_key','user_id')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- basket_id: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- sales_value: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- retail_disc: string (nullable = true)\n",
      " |-- trans_time: string (nullable = true)\n",
      " |-- week_no: string (nullable = true)\n",
      " |-- coupon_disc: string (nullable = true)\n",
      " |-- coupon_match_disc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---+-------+--------+-----------+--------+-----------+-------+-----------+-----------------+\n",
      "|user_id|basket_id|day|item_id|quantity|sales_value|store_id|retail_disc|week_no|coupon_disc|coupon_match_disc|\n",
      "+-------+---------+---+-------+--------+-----------+--------+-----------+-------+-----------+-----------------+\n",
      "|   2375|     null|  1|1004906|       1|       1.39|     364|       -0.6|      1|          0|              0.0|\n",
      "|   2375|     null|  1|1033142|       1|       0.82|     364|        0.0|      1|          0|              0.0|\n",
      "|   2375|     null|  1|1036325|       1|       0.99|     364|       -0.3|      1|          0|              0.0|\n",
      "+-------+---------+---+-------+--------+-----------+--------+-----------+-------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.\\\n",
    "    withColumn('user_id', col('user_id').cast('integer')).\\\n",
    "    withColumn('basket_id', col('basket_id').cast('integer')).\\\n",
    "    withColumn('day', col('day').cast('integer')).\\\n",
    "    withColumn('item_id', col('item_id').cast('integer')).\\\n",
    "    withColumn('quantity', col('quantity').cast('integer')).\\\n",
    "    withColumn('sales_value', col('sales_value').cast('float')).\\\n",
    "    withColumn('store_id', col('store_id').cast('integer')).\\\n",
    "    withColumn('retail_disc', col('retail_disc').cast('float')).\\\n",
    "    withColumn('week_no', col('week_no').cast('integer')).\\\n",
    "    withColumn('coupon_disc', col('coupon_disc').cast('integer')).\\\n",
    "    withColumn('coupon_match_disc', col('coupon_match_disc').cast('float')).\\\n",
    "    drop('trans_time')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_weeks = 7\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - val_lvl_1_size_weeks]\n",
    "data_test = data[(data['week_no'] >= data['week_no'].max() - val_lvl_1_size_weeks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   414| 2698|\n",
      "|   599| 2478|\n",
      "|   474| 2108|\n",
      "|   448| 1864|\n",
      "|   274| 1346|\n",
      "|   610| 1302|\n",
      "|    68| 1260|\n",
      "|   380| 1218|\n",
      "|   606| 1115|\n",
      "|   288| 1055|\n",
      "|   249| 1046|\n",
      "|   387| 1027|\n",
      "|   182|  977|\n",
      "|   307|  975|\n",
      "|   603|  943|\n",
      "|   298|  939|\n",
      "|   177|  904|\n",
      "|   318|  879|\n",
      "|   232|  862|\n",
      "|   480|  836|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "userId_ratings = ratings.groupBy(\"userId\").count().orderBy('count', ascending=False)\n",
    "userId_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    356|  329|\n",
      "|    318|  317|\n",
      "|    296|  307|\n",
      "|    593|  279|\n",
      "|   2571|  278|\n",
      "|    260|  251|\n",
      "|    480|  238|\n",
      "|    110|  237|\n",
      "|    589|  224|\n",
      "|    527|  220|\n",
      "|   2959|  218|\n",
      "|      1|  215|\n",
      "|   1196|  211|\n",
      "|     50|  204|\n",
      "|   2858|  204|\n",
      "|     47|  203|\n",
      "|    780|  202|\n",
      "|    150|  201|\n",
      "|   1198|  200|\n",
      "|   4993|  198|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "movieId_ratings = ratings.groupBy(\"movieId\").count().orderBy('count', ascending=False)\n",
    "movieId_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Out An ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False, coldStartStrategy=\"drop\")\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tell Spark how to tune your ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .build()\n",
    "            #             .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_54c5bf88093f\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model and Best Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "**Best Model**\n",
      "  Rank: 50\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# # Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656510561406606\n"
     ]
    }
   ],
   "source": [
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   385|    471|   4.0| 3.2817402|\n",
      "|   462|    471|   2.5| 2.3096857|\n",
      "|   387|    471|   3.0| 3.0138159|\n",
      "|   171|    471|   3.0| 4.4921217|\n",
      "|    32|    471|   3.0| 3.7683742|\n",
      "|   469|    471|   5.0| 3.4463875|\n",
      "|   357|    471|   3.5| 3.9890354|\n",
      "|   132|   1088|   4.0|  2.749427|\n",
      "|   563|   1088|   4.0| 3.3631582|\n",
      "|   594|   1088|   4.5| 4.3264866|\n",
      "|   307|   1088|   3.0| 2.4013104|\n",
      "|    51|   1088|   4.0| 3.8586433|\n",
      "|   221|   1088|   3.0|  3.030849|\n",
      "|   414|   1088|   3.0| 3.0015788|\n",
      "|   200|   1088|   4.0|  3.657487|\n",
      "|   104|   1088|   3.0| 3.6541252|\n",
      "|    19|   1238|   3.0|   3.22746|\n",
      "|   156|   1238|   4.0| 3.9635246|\n",
      "|   425|   1342|   3.5| 2.1818767|\n",
      "|   600|   1342|   2.5| 2.2087283|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[3379, 4.6728826...|\n",
      "|   463|[[3379, 4.8718524...|\n",
      "|   496|[[3379, 4.521693]...|\n",
      "|   148|[[93008, 4.373521...|\n",
      "|   540|[[3379, 5.3770757...|\n",
      "|   392|[[8477, 4.665325]...|\n",
      "|   243|[[86237, 5.364011...|\n",
      "|    31|[[93988, 4.960051...|\n",
      "|   516|[[3379, 4.789225]...|\n",
      "|   580|[[3379, 4.6298943...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate n Recommendations for all users\n",
    "nrecommendations = best_model.recommendForAllUsers(10)\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|   471|   3379|4.6728826|\n",
      "|   471| 102217| 4.586662|\n",
      "|   471|  92494| 4.586662|\n",
      "|   471|  89904|4.4644165|\n",
      "|   471| 171495| 4.357144|\n",
      "|   471|   8477|4.3503823|\n",
      "|   471|   6442| 4.349947|\n",
      "|   471|   7767|4.3328934|\n",
      "|   471|   7748|  4.32773|\n",
      "|   471|  26326| 4.322282|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecommendations = nrecommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the recommendations make sense?\n",
    "Lets merge movie name and genres to teh recommendation matrix for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|   rating|               title|              genres|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "|  93008|   100|4.9257135|Very Potter Seque...|      Comedy|Musical|\n",
      "|  77846|   100|4.9257135| 12 Angry Men (1997)|         Crime|Drama|\n",
      "|  25906|   100|4.9257135|Mr. Skeffington (...|       Drama|Romance|\n",
      "|   3379|   100| 4.891129| On the Beach (1959)|               Drama|\n",
      "|  69069|   100| 4.886154|     Fired Up (2009)|              Comedy|\n",
      "|  74282|   100| 4.857362|Anne of Green Gab...|Children|Drama|Ro...|\n",
      "|  93988|   100|4.8486333|North & South (2004)|       Drama|Romance|\n",
      "|   3086|   100| 4.841063|Babes in Toyland ...|Children|Comedy|F...|\n",
      "|  74226|   100|4.8314667|Dream of Light (a...|   Documentary|Drama|\n",
      "|  84273|   100|4.8314667|Zeitgeist: Moving...|         Documentary|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecommendations.join(movies, on='movieId').filter('userId = 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|   1101|   100|   5.0|      Top Gun (1986)|      Action|Romance|\n",
      "|   1958|   100|   5.0|Terms of Endearme...|        Comedy|Drama|\n",
      "|   2423|   100|   5.0|Christmas Vacatio...|              Comedy|\n",
      "|   4041|   100|   5.0|Officer and a Gen...|       Drama|Romance|\n",
      "|   5620|   100|   5.0|Sweet Home Alabam...|      Comedy|Romance|\n",
      "|    368|   100|   4.5|     Maverick (1994)|Adventure|Comedy|...|\n",
      "|    934|   100|   4.5|Father of the Bri...|              Comedy|\n",
      "|    539|   100|   4.5|Sleepless in Seat...|Comedy|Drama|Romance|\n",
      "|     16|   100|   4.5|       Casino (1995)|         Crime|Drama|\n",
      "|    553|   100|   4.5|    Tombstone (1993)|Action|Drama|Western|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.join(movies, on='movieId').filter('userId = 100').sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
